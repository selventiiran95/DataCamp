{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning with GridSearchCV\n",
    "Hugo demonstrated how to tune the `n_neighbors` parameter of the `KNeighborsClassifier()` using GridSearchCV on the voting dataset. You will now practice this yourself, but by using logistic regression on the diabetes dataset instead!\n",
    "\n",
    "Like the alpha parameter of lasso and ridge regularization that you saw earlier, logistic regression also has a regularization parameter: ***C***. ***C*** controls the inverse of the regularization strength, and this is what you will tune in this exercise. A large ***C*** can lead to an overfit model, while a small ***C*** can lead to an underfit model.\n",
    "\n",
    "The hyperparameter space for ***C*** has been setup for you. Your job is to use GridSearchCV and logistic regression to find the optimal ***C*** in this hyperparameter space. The feature array is available as `X` and target variable array is available as `y`.\n",
    "\n",
    "You may be wondering why you aren't asked to split the data into training and test sets. Good observation! Here, we want you to focus on the process of setting up the hyperparameter grid and performing grid-search cross-validation. In practice, you will indeed want to hold out a portion of your data for evaluation purposes, and you will learn all about this in the next video!\n",
    "\n",
    "### Instructions:\n",
    "* Import `LogisticRegression` from `sklearn.linear_model` and `GridSearchCV` from `sklearn.model_selection`.\n",
    "* Setup the hyperparameter grid by using `c_space` as the grid of values to tune ***C*** over.\n",
    "* Instantiate a logistic regression classifier called `logreg`.\n",
    "* Use `GridSearchCV` with 5-fold cross-validation to tune ***C***:\n",
    "    * Inside `GridSearchCV()`, specify the classifier, parameter grid, and number of folds to use.\n",
    "    * Use the `.fit()` method on the GridSearchCV object to fit it to the data `X` and `y`.\n",
    "* Print the best parameter and best score obtained from `GridSearchCV` by accessing the `best_params_` and `best_score_` attributes of `logreg_cv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Setup the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space}\n",
    "\n",
    "# Instantiate a logistic regression classifier: logreg\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "logreg_cv.fit(X, y)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_)) \n",
    "print(\"Best score is {}\".format(logreg_cv.best_score_))\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
